{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767d8144-50be-4fe1-8b44-2f287f9e6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from typing import Dict \n",
    "\n",
    "\n",
    "import ray\n",
    "# from ray import air, tune\n",
    "# from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "import rtdl\n",
    "from tablebench.core import TabularDataset, TabularDatasetConfig\n",
    "\n",
    "from tablebench.datasets.experiment_configs import EXPERIMENT_CONFIGS\n",
    "from tablebench.models import get_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72d8f42-e986-4479-bcbd-33d69f3d23c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] not downloading https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data; exists at tmp/adult.data\n",
      "[DEBUG] not downloading https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names; exists at tmp/adult.names\n",
      "[DEBUG] not downloading https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test; exists at tmp/adult.test\n",
      "[DEBUG] dropping data columns not in FeatureList: ['fnlwgt']\n",
      "[DEBUG] checking feature Age\n",
      "[DEBUG] casting feature Age from dtype int64 to dtype float\n",
      "[DEBUG] checking feature Workclass\n",
      "[DEBUG] casting feature Workclass from dtype object to dtype CategoricalDtype\n",
      "[DEBUG] checking feature Education-Num\n",
      "[DEBUG] casting feature Education-Num from dtype int64 to dtype CategoricalDtype\n",
      "[DEBUG] checking feature Marital Status\n",
      "[DEBUG] casting feature Marital Status from dtype object to dtype CategoricalDtype\n",
      "[DEBUG] checking feature Occupation\n",
      "[DEBUG] casting feature Occupation from dtype object to dtype CategoricalDtype\n",
      "[DEBUG] checking feature Relationship\n",
      "[DEBUG] casting feature Relationship from dtype object to dtype CategoricalDtype\n",
      "[DEBUG] checking feature Race\n",
      "[DEBUG] casting feature Race from dtype object to dtype CategoricalDtype\n",
      "[DEBUG] checking feature Sex\n",
      "[DEBUG] casting feature Sex from dtype object to dtype CategoricalDtype\n",
      "[DEBUG] checking feature Capital Gain\n",
      "[DEBUG] casting feature Capital Gain from dtype int64 to dtype float\n",
      "[DEBUG] checking feature Capital Loss\n",
      "[DEBUG] casting feature Capital Loss from dtype int64 to dtype float\n",
      "[DEBUG] checking feature Hours per week\n",
      "[DEBUG] casting feature Hours per week from dtype int64 to dtype float\n",
      "[DEBUG] checking feature Country\n",
      "[DEBUG] casting feature Country from dtype object to dtype CategoricalDtype\n",
      "[DEBUG] checking feature Target\n",
      "[DEBUG] dropped 0 rows containing missing values (0.0% of data).\n",
      "[DEBUG] overall counts after grouping:\n",
      "Sex       0      1\n",
      "Race              \n",
      "0      3165   3915\n",
      "1     13027  28735\n",
      "[DEBUG] printing post-transform feature summary\n",
      "scale_Age__Age: mean 0.0032136191643880267, std 1.0080549617309507\n",
      "scale_Capital Gain__Capital Gain: mean 9.933609069753339e-05, std 1.0186280300324413\n",
      "scale_Capital Loss__Capital Loss: mean 0.0016719474040243652, std 1.0032166136534697\n",
      "scale_Hours per week__Hours per week: mean -0.0008620172387195973, std 1.005486135774981\n"
     ]
    }
   ],
   "source": [
    "experiment = \"adult\"\n",
    "expt_config = EXPERIMENT_CONFIGS[experiment]\n",
    "\n",
    "dataset_config = TabularDatasetConfig()\n",
    "dset = TabularDataset(experiment,\n",
    "                      config=dataset_config,\n",
    "                      splitter=expt_config.splitter,\n",
    "                      grouper=expt_config.grouper,\n",
    "                      preprocessor_config=expt_config.preprocessor_config,\n",
    "                      **expt_config.tabular_dataset_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2669a10-fc02-4a53-a709-b84720944e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ray_dataset(dset: TabularDataset, split):\n",
    "    X, y, G, _ = dset.get_pandas(split)\n",
    "    df = pd.concat([X, y, G], axis=1)\n",
    "    df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "\n",
    "    y_name = y.name\n",
    "    G_names = G.columns.tolist()\n",
    "    X_names = X.columns.tolist()\n",
    "\n",
    "    y_tr = pd.DataFrame(y)\n",
    "\n",
    "    dataset: ray.data.Dataset = ray.data.from_pandas([df])\n",
    "    return dataset\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def unpack_row(row) -> List:\n",
    "    \"Convert PandasRow to a dict of numpy arrays.\"\n",
    "    x = row[X_names].values.astype(float)\n",
    "    y = row[y_name].values.astype(float)\n",
    "    g = row[G_names].values.astype(float)\n",
    "    return {\"x\": x, \"y\": y, \"g\": g}\n",
    "\n",
    "def _tmp_fn(x):\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "train_dataset = make_ray_dataset(dset, \"train\")\n",
    "train_dataset = train_dataset.map_batches(unpack_row, batch_format=\"pandas\")\n",
    "\n",
    "val_dataset = make_ray_dataset(dset, \"validation\")\n",
    "val_dataset = val_dataset.map_batches(unpack_row, batch_format=\"pandas\")\n",
    "\n",
    "# # show one element\n",
    "# r = train_dataset.take(1)[0]\n",
    "# print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee977428-a687-4f23-88ca-ec6b43b08e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-01 14:09:11</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:44.08        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.6/8.0 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/2.14 GiB heap, 0.0/1.07 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">    train_loop_config/d_\n",
       "hidden</th><th style=\"text-align: right;\">  train_loop_config/lr</th><th style=\"text-align: right;\">  train_loop_config/nu\n",
       "m_layers</th><th style=\"text-align: right;\">           train_loop_config/we\n",
       "ight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  validation_accuracy</th><th style=\"text-align: right;\">  _timestamp</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_c7007_00000</td><td>TERMINATED</td><td>127.0.0.1:32064</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">           0.000185141</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00512622</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         44.9865</td><td style=\"text-align: right;\">     326.86 </td><td style=\"text-align: right;\">             0.855546</td><td style=\"text-align: right;\">  1669925300</td></tr>\n",
       "<tr><td>TorchTrainer_c7007_00001</td><td>TERMINATED</td><td>127.0.0.1:32080</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">           0.00532164 </td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00142488</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         36.0985</td><td style=\"text-align: right;\">     333.197</td><td style=\"text-align: right;\">             0.855669</td><td style=\"text-align: right;\">  1669925348</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32068)\u001b[0m 2022-12-01 14:07:41,139\tINFO config.py:87 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32069)\u001b[0m /Users/jpgard/opt/miniconda3/envs/tableshift/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:135: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32069)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32068)\u001b[0m 2022-12-01 14:07:45,058\tINFO train_loop_utils.py:298 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32068)\u001b[0m 2022-12-01 14:07:45,058\tINFO train_loop_utils.py:362 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32068)\u001b[0m /Users/jpgard/opt/miniconda3/envs/tableshift/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:135: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32068)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32068)\u001b[0m starting epoch 0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32069)\u001b[0m starting epoch 0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32068)\u001b[0m [1,  2000] loss: 0.347\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32069)\u001b[0m [1,  2000] loss: 0.337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">  _time_this_iter_s</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _training_iteration</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>experiment_tag                                           </th><th>hostname                    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  validation_accuracy</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_c7007_00000</td><td style=\"text-align: right;\">            18.6489</td><td style=\"text-align: right;\">  1669925300</td><td style=\"text-align: right;\">                    2</td><td>2022-12-01_14-08-21</td><td>True  </td><td>                </td><td>0131cf2b9b14427ba52a755565e875e8</td><td>0_d_hidden=256,lr=0.0002,num_layers=3,weight_decay=0.0051</td><td>Joshuas-MacBook-Pro-10.local</td><td style=\"text-align: right;\">                         2</td><td>127.0.0.1</td><td style=\"text-align: right;\">32064</td><td>True               </td><td style=\"text-align: right;\">             44.9865</td><td style=\"text-align: right;\">           18.6616</td><td style=\"text-align: right;\">       44.9865</td><td style=\"text-align: right;\"> 1669925301</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">     326.86 </td><td style=\"text-align: right;\">                   2</td><td>c7007_00000</td><td style=\"text-align: right;\">             0.855546</td><td style=\"text-align: right;\">      1.64972</td></tr>\n",
       "<tr><td>TorchTrainer_c7007_00001</td><td style=\"text-align: right;\">            13.2529</td><td style=\"text-align: right;\">  1669925348</td><td style=\"text-align: right;\">                    2</td><td>2022-12-01_14-09-08</td><td>True  </td><td>                </td><td>95ecffe44c9740da83711808e8f3d1df</td><td>1_d_hidden=64,lr=0.0053,num_layers=2,weight_decay=0.0014 </td><td>Joshuas-MacBook-Pro-10.local</td><td style=\"text-align: right;\">                         2</td><td>127.0.0.1</td><td style=\"text-align: right;\">32080</td><td>True               </td><td style=\"text-align: right;\">             36.0985</td><td style=\"text-align: right;\">           12.6639</td><td style=\"text-align: right;\">       36.0985</td><td style=\"text-align: right;\"> 1669925348</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">     333.197</td><td style=\"text-align: right;\">                   2</td><td>c7007_00001</td><td style=\"text-align: right;\">             0.855669</td><td style=\"text-align: right;\">      1.1508 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32068)\u001b[0m starting epoch 1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32069)\u001b[0m starting epoch 1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32068)\u001b[0m [2,  2000] loss: 0.315\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32069)\u001b[0m [2,  2000] loss: 0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32084)\u001b[0m 2022-12-01 14:08:36,885\tINFO config.py:87 -- Setting up process group for: env:// [rank=0, world_size=2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32085)\u001b[0m starting epoch 0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32084)\u001b[0m starting epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32085)\u001b[0m /Users/jpgard/opt/miniconda3/envs/tableshift/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:135: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32085)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32084)\u001b[0m 2022-12-01 14:08:42,246\tINFO train_loop_utils.py:298 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32084)\u001b[0m 2022-12-01 14:08:42,246\tINFO train_loop_utils.py:362 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32084)\u001b[0m /Users/jpgard/opt/miniconda3/envs/tableshift/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:135: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32084)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32085)\u001b[0m [1,  2000] loss: 0.332\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32084)\u001b[0m [1,  2000] loss: 0.345\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32085)\u001b[0m starting epoch 1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32084)\u001b[0m starting epoch 1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32085)\u001b[0m [2,  2000] loss: 0.314\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=32084)\u001b[0m [2,  2000] loss: 0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 14:09:11,272\tINFO tune.py:777 -- Total run time: 104.26 seconds (104.07 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune import Tuner \n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.air.config import RunConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "from ray import train\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.train.torch import TorchCheckpoint\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import sklearn\n",
    "import scipy\n",
    "from typing import Tuple\n",
    "\n",
    "def _cat_preds(prediction):\n",
    "    # print(f\"[JG] predictions shape is {[x.shape for x in prediction]}\")\n",
    "    return torch.cat(prediction).squeeze().cpu().numpy()\n",
    "\n",
    "def _cat_labs(label):\n",
    "    # print(f\"[JG] label shape is {[x.shape for x in label]}\")\n",
    "    return torch.cat(label).squeeze().cpu().numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_predictions_and_labels(model, loader, as_logits=False) -> Tuple[\n",
    "    np.ndarray, np.ndarray]:\n",
    "    \"\"\"Get the predictions (as logits, or probabilities) and labels.\"\"\"\n",
    "    prediction = []\n",
    "    label = []\n",
    "\n",
    "    for batch in loader:\n",
    "        batch_x, batch_y = batch[\"x\"], batch[\"y\"]\n",
    "        batch_x = batch_x.float()\n",
    "        batch_y = batch_y.float()\n",
    "        # TODO(jpgard): handle categorical features here.\n",
    "        prediction.append(model(batch_x))\n",
    "        label.append(batch_y)\n",
    "    # prediction = torch.cat(prediction).squeeze().cpu().numpy()\n",
    "    prediction = _cat_preds(prediction)\n",
    "    # target = torch.cat(label).squeeze().cpu().numpy()\n",
    "    target = _cat_labs(label)\n",
    "    if not as_logits:\n",
    "        prediction = scipy.special.expit(prediction)\n",
    "    return prediction, target\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config: Dict):\n",
    "    model = get_estimator(\"mlp\", d_in=dset.X_shape[1], d_layers=[config[\"d_hidden\"]] * config[\"num_layers\"])\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    criterion = F.binary_cross_entropy_with_logits\n",
    "    \n",
    "    optimizer = (\n",
    "        model.make_default_optimizer()\n",
    "        if isinstance(model, rtdl.FTTransformer)\n",
    "        else torch.optim.AdamW(model.parameters(), \n",
    "                               lr=config.get(\"lr\", 0.001), \n",
    "                               weight_decay=config.get(\"weight_decay\", 0.)))\n",
    "\n",
    "    train_dataset_shard = session.get_dataset_shard(\"train\")\n",
    "    val_dataset_shard = session.get_dataset_shard(\"validation\")\n",
    "    \n",
    "    # TODO(jpgard): call model.train_epoch() instead of the training logic below.\n",
    "    \n",
    "    # Returns the current torch device; useful for sending to a device.\n",
    "    # train.torch.get_device()\n",
    "    \n",
    "    for epoch in range(2):\n",
    "        model.train()\n",
    "        print(f\"starting epoch {epoch}\")\n",
    "        running_loss = 0.0\n",
    "        train_dataset_batches = train_dataset_shard.iter_torch_batches(batch_size=config[\"batch_size\"])\n",
    "        for i, batch in enumerate(train_dataset_batches):\n",
    "            # get the inputs and labels\n",
    "            inputs, labels, groups = batch[\"x\"], batch[\"y\"], batch[\"g\"]\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\")\n",
    "                running_loss = 0.0\n",
    "        # compute the validation accuracy\n",
    "        model.eval()\n",
    "        prediction, target = get_predictions_and_labels(\n",
    "            model, \n",
    "            val_dataset_shard.iter_torch_batches(batch_size=config[\"batch_size\"]))\n",
    "        prediction = np.round(prediction)\n",
    "        val_acc = sklearn.metrics.accuracy_score(target, prediction)\n",
    "        \n",
    "        # Log the metrics for this epoch\n",
    "        metrics = dict(train_loss=running_loss, validation_accuracy=val_acc)\n",
    "        checkpoint = TorchCheckpoint.from_state_dict(model.module.state_dict())\n",
    "        session.report(metrics, checkpoint=checkpoint)\n",
    "\n",
    "\n",
    "# Hyperparameter search space; note that the scaling_config can also be tuned\n",
    "# but is fixed here.\n",
    "param_space = {\n",
    "    # The params will be merged with the ones defined in the TorchTrainer\n",
    "    \"train_loop_config\": {\n",
    "        # This is a parameter that hasn't been set in the TorchTrainer\n",
    "        \"num_layers\": tune.randint(1, 4),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"weight_decay\": tune.loguniform(1e-4, 1e0),\n",
    "        \"d_hidden\": tune.choice([64, 128, 256, 512]),\n",
    "        # This will overwrite whatever was set when TorchTrainer was instantiated\n",
    "        # \"batch_size\": tune.choice([4, 8]),\n",
    "    },\n",
    "    # Tune the number of distributed workers\n",
    "    \"scaling_config\": ScalingConfig(num_workers=2),\n",
    "    \n",
    "    # Note: when num_workers=1, trials seemed to fail with AttributeError \n",
    "    # (MLPModel does not have attribute 'module'); not sure why.\n",
    "    # \"scaling_config\": ScalingConfig(num_workers=tune.grid_search([1, 2])),\n",
    "}\n",
    "\n",
    "# Trainer object that will be passed to each worker.\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\"batch_size\": 4, \"epochs\": 5},\n",
    "    datasets={\"train\": train_dataset, \"validation\": val_dataset},\n",
    "    scaling_config=ScalingConfig(num_workers=2, use_gpu=False),\n",
    ")\n",
    "\n",
    "# To run just a single training iteration (without tuning), can run:\n",
    "# result = trainer.fit()\n",
    "# latest_checkpoint = result.checkpoint\n",
    "\n",
    "# Create Tuner\n",
    "tuner = Tuner(\n",
    "    trainable=trainer,\n",
    "    run_config=RunConfig(name=\"test_tuner_notebook\", local_dir=\"ray-results\"),\n",
    "    param_space=param_space,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        # search_alg=HyperOptSearch(),\n",
    "        # scheduler=ASHAScheduler(time_attr='training_iteration', \n",
    "        #                     metric=\"train_loss\", \n",
    "        #                     mode=\"min\", \n",
    "        #                     max_t=100, \n",
    "        #                     grace_period=1, \n",
    "        #                     reduction_factor=4, \n",
    "        #                     brackets=1, \n",
    "        #                     stop_last_trials=True),\n",
    "        mode=\"min\", metric=\"train_loss\", \n",
    "        num_samples=2, max_concurrent_trials=2),\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56ea35ce-898d-4f5a-a125-f02e8f99d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'train_loop_config': {'num_layers': 3, 'lr': 0.0001851412960649755, 'weight_decay': 0.005126223049159909, 'd_hidden': 256}, 'scaling_config': {'trainer_resources': None, 'num_workers': 2, 'use_gpu': False, 'resources_per_worker': None, 'placement_strategy': 'PACK', '_max_cpu_fraction_per_node': None}}\n",
      "Best trial final loss: 326.8599194509443\n"
     ]
    }
   ],
   "source": [
    "best_result = results.get_best_result(\"train_loss\", \"min\")\n",
    "\n",
    "print(\"Best trial config: {}\".format(best_result.config))\n",
    "print(\"Best trial final loss: {}\".format(\n",
    "    best_result.metrics[\"train_loss\"]))\n",
    "# print(\"Best trial final validation accuracy: {}\".format(\n",
    "#     best_result.metrics[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ec14f",
   "metadata": {},
   "source": [
    "## Load and normalize CIFAR-10\n",
    "\n",
    "We'll train our classifier on a popular image dataset called [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "First, let's load CIFAR-10 into a Ray Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.data.datasource import SimpleTorchDatasource\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "\n",
    "def train_dataset_factory():\n",
    "    return torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", download=True, train=True, transform=transform\n",
    "    )\n",
    "\n",
    "\n",
    "def test_dataset_factory():\n",
    "    return torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", download=True, train=False, transform=transform\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6377be-519f-42c4-b149-0c5b3d9dd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset: ray.data.Dataset = ray.data.read_datasource(\n",
    "    SimpleTorchDatasource(), dataset_factory=train_dataset_factory\n",
    ")\n",
    "test_dataset: ray.data.Dataset = ray.data.read_datasource(\n",
    "    SimpleTorchDatasource(), dataset_factory=test_dataset_factory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b59e8",
   "metadata": {},
   "source": [
    "{py:class}`SimpleTorchDatasource <ray.data.datasource.SimpleTorchDatasource>` doesn't parallelize reads, so you shouldn't use it with larger datasets.\n",
    "\n",
    "Next, let's represent our data using a dictionary of ndarrays instead of tuples. This lets us call {py:meth}`Dataset.iter_torch_batches <ray.data.Dataset.iter_torch_batches>` later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c485ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def convert_batch_to_numpy(batch: Tuple[torch.Tensor, int]) -> Dict[str, np.ndarray]:\n",
    "    images = np.array([image.numpy() for image, _ in batch])\n",
    "    labels = np.array([label for _, label in batch])\n",
    "    return {\"image\": images, \"label\": labels}\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map_batches(convert_batch_to_numpy)\n",
    "test_dataset = test_dataset.map_batches(convert_batch_to_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cc4086",
   "metadata": {},
   "source": [
    "## Train a convolutional neural network\n",
    "\n",
    "Now that we've created our datasets, let's define the training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d85c9d",
   "metadata": {},
   "source": [
    "We define our training logic in a function called `train_loop_per_worker`. This function contains regular PyTorch code with a few notable exceptions:\n",
    "* We wrap our model with {py:func}`train.torch.prepare_model <ray.train.torch.prepare_model>`.\n",
    "* We call {py:func}`session.get_dataset_shard <ray.air.session.get_dataset_shard>` and {py:meth}`Dataset.iter_torch_batches <ray.data.Dataset.iter_torch_batches>` to get a subset of our training data.\n",
    "* We save model state using {py:func}`session.report <ray.air.session.report>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import train\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.train.torch import TorchCheckpoint\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    model = train.torch.prepare_model(Net())\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    train_dataset_shard = session.get_dataset_shard(\"train\")\n",
    "\n",
    "    for epoch in range(2):\n",
    "        running_loss = 0.0\n",
    "        train_dataset_batches = train_dataset_shard.iter_torch_batches(\n",
    "            batch_size=config[\"batch_size\"],\n",
    "        )\n",
    "        for i, batch in enumerate(train_dataset_batches):\n",
    "            # get the inputs and labels\n",
    "            inputs, labels = batch[\"image\"], batch[\"label\"]\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        metrics = dict(running_loss=running_loss)\n",
    "        checkpoint = TorchCheckpoint.from_state_dict(model.module.state_dict())\n",
    "        session.report(metrics, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58100f87",
   "metadata": {},
   "source": [
    "Finally, we can train our model. This should take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a51244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\"batch_size\": 2},\n",
    "    datasets={\"train\": train_dataset},\n",
    "    scaling_config=ScalingConfig(num_workers=2),\n",
    ")\n",
    "result = trainer.fit()\n",
    "latest_checkpoint = result.checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df4faa9",
   "metadata": {},
   "source": [
    "To scale your training script, create a [Ray Cluster](cluster-index) and increase the number of workers. If your cluster contains GPUs, add `\"use_gpu\": True` to your scaling config.\n",
    "\n",
    "```{code-block} python\n",
    "scaling_config=ScalingConfig(num_workers=8, use_gpu=True)\n",
    "```\n",
    "\n",
    "## Test the network on the test data\n",
    "\n",
    "Let's see how our model performs.\n",
    "\n",
    "To classify images in the test dataset, we'll need to create a {py:class}`Predictor <ray.train.predictor.Predictor>`.\n",
    "\n",
    "{py:class}`Predictors <ray.train.predictor.Predictor>` load data from checkpoints and efficiently perform inference. In contrast to {py:class}`TorchPredictor <ray.train.torch.TorchPredictor>`, which performs inference on a single batch, {py:class}`BatchPredictor <ray.train.batch_predictor.BatchPredictor>` performs inference on an entire dataset. Because we want to classify all of the images in the test dataset, we'll use a {py:class}`BatchPredictor <ray.train.batch_predictor.BatchPredictor>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ec534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.torch import TorchPredictor\n",
    "from ray.train.batch_predictor import BatchPredictor\n",
    "\n",
    "batch_predictor = BatchPredictor.from_checkpoint(\n",
    "    checkpoint=latest_checkpoint,\n",
    "    predictor_cls=TorchPredictor,\n",
    "    model=Net(),\n",
    ")\n",
    "\n",
    "outputs: ray.data.Dataset = batch_predictor.predict(\n",
    "    data=test_dataset,\n",
    "    dtype=torch.float,\n",
    "    feature_columns=[\"image\"],\n",
    "    keep_columns=[\"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20fd044",
   "metadata": {},
   "source": [
    "Our model outputs a list of energies for each class. To classify an image, we\n",
    "choose the class that has the highest energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c8a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def convert_logits_to_classes(df):\n",
    "    best_class = df[\"predictions\"].map(lambda x: x.argmax())\n",
    "    df[\"prediction\"] = best_class\n",
    "    return df[[\"prediction\", \"label\"]]\n",
    "\n",
    "\n",
    "predictions = outputs.map_batches(convert_logits_to_classes)\n",
    "\n",
    "predictions.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973efc6",
   "metadata": {},
   "source": [
    "Now that we've classified all of the images, let's figure out which images were\n",
    "classified correctly. The ``predictions`` dataset contains predicted labels and \n",
    "the ``test_dataset`` contains the true labels. To determine whether an image \n",
    "was classified correctly, we join the two datasets and check if the predicted \n",
    "labels are the same as the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6233ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction_scores(df):\n",
    "    df[\"correct\"] = df[\"prediction\"] == df[\"label\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "scores = predictions.map_batches(calculate_prediction_scores)\n",
    "\n",
    "scores.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d401d91",
   "metadata": {},
   "source": [
    "To compute our test accuracy, we'll count how many images the model classified \n",
    "correctly and divide that number by the total number of test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.sum(on=\"correct\") / scores.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c84e2c",
   "metadata": {},
   "source": [
    "## Deploy the network and make a prediction\n",
    "\n",
    "Our model seems to perform decently, so let's deploy the model to an \n",
    "endpoint. This allows us to make predictions over the Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2faaf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import serve\n",
    "from ray.serve import PredictorDeployment\n",
    "from ray.serve.http_adapters import json_to_ndarray\n",
    "\n",
    "\n",
    "serve.run(\n",
    "    PredictorDeployment.bind(\n",
    "        TorchPredictor,\n",
    "        latest_checkpoint,\n",
    "        model=Net(),\n",
    "        http_adapter=json_to_ndarray,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90327e8a",
   "metadata": {},
   "source": [
    "Let's classify a test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = test_dataset.take(1)[0][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d94b7",
   "metadata": {},
   "source": [
    "You can perform inference against a deployed model by posting a dictionary with an `\"array\"` key. To learn more about the default input schema, read the {py:class}`NdArray <ray.serve.http_adapters.NdArray>` documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd85d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = {\"array\": image.tolist(), \"dtype\": \"float32\"}\n",
    "response = requests.post(\"http://localhost:8000/\", json=payload)\n",
    "response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a658351b4133f922c5967ed6133cfc05c9f16c53a5161e5843ace3f528fccaf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
